{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FUENTES**:\n",
    "\n",
    "PetFinder Kaggle:\n",
    "\n",
    "https://www.kaggle.com/competitions/petfinder-adoption-prediction/data\n",
    "\n",
    "First Tutorial:\n",
    "\n",
    "https://towardsdatascience.com/how-to-train-an-image-classifier-in-pytorch-and-use-it-to-perform-basic-inference-on-single-images-99465a1e9bf5\n",
    "\n",
    "Second Deep Tutorial:\n",
    "\n",
    "https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e\n",
    "\n",
    "Logo Recognition API:\n",
    "\n",
    "https://heartbeat.comet.ml/logo-recognition-ios-application-using-machine-learning-and-flask-api-aec4eff3be11\n",
    "\n",
    "Hybrid (multimodal) neural network architecture : Combination of tabular, textual and image inputs:\n",
    "\n",
    "https://medium.com/@dave.cote.msc/hybrid-multimodal-neural-network-architecture-combination-of-tabular-textual-and-image-inputs-7460a4f82a2e\n",
    "\n",
    "\n",
    "\n",
    "### **INDICACIONES PREVIAS**:\n",
    "\n",
    "+ **Git**:\n",
    "    + Clonamos el repo: root de todos los repos y ponemos git clone \"url_repo\"\n",
    "    + Hacemos el checkout de la rama main: git checkout -b new-branch\n",
    "\n",
    "+ **Poetry**:\n",
    "    + Instalamos poetry: https://python-poetry.org/docs/\n",
    "    + Realizamos un Update del pyproject: poetry update\n",
    "    + Activamos el entorno que creo poetry: poetry shell\n",
    "    + Intentamos correr una celda, si nos pide seleccionar el environment y no lo vemos en la lista, cerrar y volver abrir VSC\n",
    "\n",
    "+ **Torch y CUDA**:\n",
    "    + Verificar que versión pide torch:\n",
    "        + Versión de torch instalada: poetry show (en mi caso la 1.13.1)\n",
    "        + Buscar la versión correspondiente en la documentación: https://pytorch.org/get-started/previous-versions/  (en mi caso el 11.7)\n",
    "    + Instalar CUDA para Torch (buscar la versión correspondiente de CUDA): https://developer.nvidia.com/cuda-11-7-0-download-archive\n",
    "    + Verificar que CUDA esté funcional: correr en una celda torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import cv2\n",
    "#from PIL import Image\n",
    "#from pathlib import Path\n",
    "\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from joblib import load, dump\n",
    "\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "# Appendeo el directorio de una carpeta arriba\n",
    "nb_dir = os.path.dirname(os.path.abspath(\"05_Resnet50_3_train_augment.ipynb\"))\n",
    "dir = os.path.abspath(os.path.join(nb_dir,'..'))\n",
    "sys.path.append(dir)\n",
    "\n",
    "from augment.autoaugment import ImageNetPolicy\t\n",
    "from augment.cutout import Cutout\n",
    "# Verificamos que CUDA está funcional\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo el Modelo**\n",
    "\n",
    "Teoría de Resnet: https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo modelo ResNet entrenado en Imagenet\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# Modificar la última capa para adaptarse a tu problema específico\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = torch.nn.Linear(num_ftrs, 5) # Clasificación 5 clases\n",
    "# Configuro para usar cuda si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)\n",
    "# Instancio del criterio de pérdida CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Instancio Stochastic Gradient Descent (SGD): Defino el parámetro del Learning Rate (define \"el paso\" en que avanzan los pesos en cada iteración) y el Momentum (pone innercia a la dirección del gradiente descendiente para que no cambie de dirección en minimos locales)\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9) # Parámetros default del SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo parámetros, directorios y funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = './'\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_IMAGES_DIR = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train_images\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_artifacts\")\n",
    "\n",
    "MODEL_NAME = '04 ResNet'\n",
    "\n",
    "MODEL_VERSION = '1.0.0'\n",
    "\n",
    "# Parametros y variables\n",
    "CREATE_PYTORCH_DIRECTORIES = 1\n",
    "SEED = 42\n",
    "BATCH_SIZE = 50\n",
    "TEST_SIZE = 0.2\n",
    "IMAGE_SIZE = 299\n",
    "CPU_CORES = os.cpu_count()\n",
    "\n",
    "# Armo el nuevo directorio de train\n",
    "new_train_directory = os.path.join(BASE_DIR, 'UA_MDM_LDI_II/work/train_images_classes')\n",
    "os.makedirs(new_train_directory, exist_ok=True) # si ya existe el nombre, lo deja como está\n",
    "\n",
    "# Armo el nuevo directorio de validación\n",
    "new_val_directory = os.path.join(BASE_DIR, 'UA_MDM_LDI_II/work/val_images_classes')\n",
    "os.makedirs(new_val_directory, exist_ok=True)\n",
    "\n",
    "# Definir las clases ordenadas\n",
    "class_names = ['0', '1', '2', '3', '4']\n",
    "\n",
    "# Mapear las etiquetas de las clases a números enteros consecutivos\n",
    "class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Creo las carpetas de clases dentro de los directorios\n",
    "for clase in class_names: # Una para cada clase\n",
    "   os.makedirs(os.path.join(new_train_directory, str(clase)), exist_ok=True)\n",
    "   os.makedirs(os.path.join(new_val_directory, str(clase)), exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Funciones para la carga y el preproceso\n",
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    # Calcula el factor de escala necesario para redimensionar la imagen de manera que el lado más largo tenga el tamaño deseado \n",
    "    ratio = float(IMAGE_SIZE)/max(old_size)\n",
    "    # Calcula las nuevas dimensiones de la imagen \n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # Redimensiona la imagen con el nuevo tamaño\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    # Calcula las diferencias de tamaño y agrega pixeles (color negro) en los extremos para que quede centrada y cuadrada \n",
    "    delta_w = IMAGE_SIZE - new_size[1]\n",
    "    delta_h = IMAGE_SIZE - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_image = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def load_image(pet_id):\n",
    "    path_to_image = os.path.join(PATH_TO_IMAGES_DIR, f'{pet_id}-1.jpg') # Irá a la primera imagen de la mascota\n",
    "    image = cv2.imread(path_to_image)\n",
    "    # Convierte la imagen de BGR a RGB porque estos modelos esperan ese orden de canales\n",
    "    image = cv2.convertScaleAbs(image)\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    new_image = resize_to_square(image)\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_pet(pet_id):\n",
    "    path_to_image = os.path.join(PATH_TO_IMAGES_DIR, f'{pet_id}-1.jpg') # Irá a la primera imagen de la mascota\n",
    "    # Cargar la imagen\n",
    "    image_to_show = cv2.imread(path_to_image)\n",
    "    # Convertir a formato RGB\n",
    "    image_to_show = cv2.cvtColor(image_to_show, cv2.COLOR_BGR2RGB)\n",
    "    # Visualizar la imagen\n",
    "    plt.imshow(image_to_show)\n",
    "    plt.axis('off')  # No mostrar los ejes\n",
    "    plt.show()\n",
    "\n",
    "def visualize_image(image):\n",
    "    # Convierte la imagen a un formato de enteros (CV_8U)\n",
    "    image = cv2.convertScaleAbs(image)\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Visualizar la imagen\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')  # No mostrar los ejes\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargo y Proceso Data**\n",
    "\n",
    "Nota: Pytorch necesita que estén las imágenes en los distintos directorios según su clase y su participación en el training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completada la copia a:  ./UA_MDM_LDI_II/work/train_images_classes\n",
      "Completada la copia a:  ./UA_MDM_LDI_II/work/val_images_classes\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Cargo\n",
    "train_df = pd.read_csv(PATH_TO_TRAIN)\n",
    "\n",
    "# Split para validación\n",
    "train_data, val_data = train_test_split(train_df,\n",
    "                               test_size = TEST_SIZE,\n",
    "                               random_state = SEED,\n",
    "                               stratify = train_df.AdoptionSpeed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if CREATE_PYTORCH_DIRECTORIES == 1: # Poner en 0 si ya tengo las carpetas train_images_classes y val_images_classes con las imágenes copiadas\n",
    "    # Función para copiar las imágenes a los directorios correspondientes\n",
    "    def copy_imag(data, directorio_destino):\n",
    "        for index, row in data.iterrows():\n",
    "            petID = row['PetID']\n",
    "            adoption_speed = row['AdoptionSpeed']\n",
    "            \n",
    "            # Nombre del archivo de imagen\n",
    "            nombre_archivo = f\"{petID}-1.jpg\"\n",
    "            \n",
    "            # Ruta completa de la imagen de origen\n",
    "            ruta_origen = os.path.join(PATH_TO_IMAGES_DIR, nombre_archivo)\n",
    "            \n",
    "            # Ruta completa del directorio de destino\n",
    "            ruta_destino = os.path.join(directorio_destino, str(adoption_speed), nombre_archivo)\n",
    "            \n",
    "            # Verificar si el archivo de origen existe\n",
    "            if os.path.exists(ruta_origen):\n",
    "                # Copiar el archivo de origen al directorio de destino\n",
    "                shutil.copy2(ruta_origen, ruta_destino)\n",
    "        print(\"Completada la copia a: \",str(directorio_destino))\n",
    "\n",
    "    # Copiar las imágenes al directorio de train\n",
    "    copy_imag(train_data, new_train_directory)\n",
    "\n",
    "    # Copiar las imágenes al directorio de val\n",
    "    copy_imag(val_data, new_val_directory)\n",
    "\n",
    "    print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los DataLoaders\n",
    "def create_dataloaders(train_directory, val_directory, batch_size, num_workers):\n",
    "    # Transformaciones de imagen para el conjunto de entrenamiento\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        ImageNetPolicy(),  ############### LAS POLÍTICAS AUTOAUGMENT PARA IMAGENET (AUGMENT)\n",
    "        transforms.ToTensor(),\n",
    "        Cutout(n_holes=1, length = 16),   ############### CUTOUT PARA REGULARIZACIÓN (AUGMENT)\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Transformaciones de imagen para el conjunto de validación (sin data augment)\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Crear conjuntos de datos para el conjunto de entrenamiento y validación\n",
    "    conjunto_entrenamiento = datasets.ImageFolder(train_directory, transform=train_transforms)\n",
    "    conjunto_validacion = datasets.ImageFolder(val_directory, transform=val_transforms)\n",
    "\n",
    "    # Asignar las clases ordenadas al conjunto de datos\n",
    "    conjunto_entrenamiento.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "    conjunto_validacion.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "    # Crear dataloaders para el conjunto de entrenamiento y validación\n",
    "    train_dataloader = torch.utils.data.DataLoader(conjunto_entrenamiento, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_dataloader = torch.utils.data.DataLoader(conjunto_validacion, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "# Aplico las funcion de los DataLoaders\n",
    "train_dataloader, val_dataloader = create_dataloaders(new_train_directory , new_val_directory , BATCH_SIZE, CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero una lista de PetIDs con imagen en el orden en que aparecen en el data loader\n",
    "test_sample_ids = [i[0].split('/')[-1].split('-')[0] for i in val_dataloader.dataset.samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entreno**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:59<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4224 Acc: 30.72% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3921 Acc: 33.58% Kappa: 0.224\n",
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3662 Acc: 35.44% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3739 Acc: 34.14% Kappa: 0.255\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3391 Acc: 37.90% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3689 Acc: 34.68% Kappa: 0.298\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3154 Acc: 39.39% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3666 Acc: 35.35% Kappa: 0.305\n",
      "Training complete in 4m 6s\n",
      "Best val Acc: 35.35%\n",
      "Modelo guardado en ./UA_MDM_LDI_II/work/optuna_temp_artifacts/04 ResNet_1.0.0_20240619_103138.pth\n"
     ]
    }
   ],
   "source": [
    "def train_val(model, criterion, optimizer, dataloaders, datasets, device, num_epochs=20, lr=0.001, momentum = 0.9 ,trial=None):\n",
    "    \n",
    "    # Instancio Stochastic Gradient Descent (SGD): Defino el parámetro del Learning Rate (define \"el paso\" en que avanzan los pesos en cada iteración) y el Momentum (pone innercia a la dirección del gradiente descendiente para que no cambie de dirección en minimos locales)\n",
    "    optimizer = optim.SGD(resnet50.parameters(), lr=lr, momentum=momentum) # Parámetros default del SGD\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_kappa =  -999\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    try:\n",
    "        previous_best = study.best_value\n",
    "    except:\n",
    "        previous_best = -999\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        kappa_labels_true = []\n",
    "        kappa_labels_predicted = []\n",
    "        output_scores = []\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    elif phase == 'val':\n",
    "                        kappa_labels_true.extend(labels.cpu().numpy().tolist())\n",
    "                        kappa_labels_predicted.extend(preds.cpu().numpy().tolist())\n",
    "                        outputs_np = outputs.cpu().numpy()\n",
    "                        output_scores.extend([outputs_np[i,:] for i in range(outputs_np.shape[0])])\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                #END OF BATCH\n",
    "\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(datasets[phase])\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                kappa_score = np.nan\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                kappa_score = cohen_kappa_score(kappa_labels_true,\n",
    "                                  kappa_labels_predicted,\n",
    "                                  weights = 'quadratic')\n",
    "                    \n",
    "\n",
    "\n",
    "            print(f'{phase.title()} Loss: {epoch_loss:.4f} Acc: {epoch_acc*100:.2f}% Kappa: {kappa_score:.3f}')\n",
    "\n",
    "            # If this is the best Epoch so far -> Deep copy the model\n",
    "            if phase == 'val' and kappa_score > best_kappa:\n",
    "                best_acc = epoch_acc\n",
    "                best_kappa = kappa_score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "                #Best Epoch within a trial and better than previous trials\n",
    "                if trial is not None and best_kappa > previous_best:\n",
    "\n",
    "                    #Save test dataset with predictions\n",
    "                    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "                    predicted_df = pd.DataFrame({'PetID':test_sample_ids,\n",
    "                                'pred':output_scores}).merge(val_data, on='PetID')\n",
    "                    dump(predicted_df, predicted_filename)\n",
    "\n",
    "                    #Generate and save CM \n",
    "                    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "                    plot_confusion_matrix(kappa_labels_true,kappa_labels_predicted).write_image(cm_filename)\n",
    "\n",
    "            #END OF PHASE\n",
    "\n",
    "        #END OF EPOCH\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(best_acc * 100))\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Save in optuna trial the best test dataset, cm and model weights\n",
    "    if trial is not None and best_kappa > previous_best:\n",
    "        upload_artifact(trial, predicted_filename, artifact_store)   \n",
    "\n",
    "        upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "        file_name = f'{MODEL_NAME}_{MODEL_VERSION}_{trial.number}.pth'\n",
    "        model_path = os.path.join(PATH_TO_TEMP_FILES, file_name)\n",
    "        torch.save(model, model_path) # Podemos guardar solo los pesos si queremos: best_model.state_dict()\n",
    "        upload_artifact(trial, model_path, artifact_store)\n",
    "\n",
    "    return model,best_kappa\n",
    "\n",
    "best_model,_ = train_val(resnet50, criterion, optimizer,\n",
    "                       dataloaders={'train': train_dataloader, \n",
    "                                    'val': val_dataloader}, \n",
    "                       datasets={'train': train_data, 'val': val_data}, \n",
    "                       device=device, \n",
    "                       num_epochs=4)\n",
    "# Guardo el modelo\n",
    "run_id = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f'{MODEL_NAME}_{MODEL_VERSION}_{run_id}.pth'\n",
    "model_path = os.path.join(PATH_TO_TEMP_FILES, file_name)\n",
    "torch.save(best_model, model_path) # Podemos guardar solo los pesos si queremos: best_model.state_dict()\n",
    "print(f'Modelo guardado en {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1691189/3870832202.py:1: ExperimentalWarning: FileSystemArtifactStore is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "  artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n"
     ]
    }
   ],
   "source": [
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "\n",
    "def optuna_train(trial):\n",
    "\n",
    "    epochs = trial.suggest_int('epochs', 5, 5)\n",
    "\n",
    "    lr = trial.suggest_float('lr', 0.00001, 0.1, log=True)\n",
    "\n",
    "    momentum = trial.suggest_float('momentum', 0.0, 0.95)\n",
    "\n",
    "    _,best_score = train_val(resnet50, criterion, optimizer,\n",
    "                       dataloaders={'train': train_dataloader, \n",
    "                                    'val': val_dataloader}, \n",
    "                       datasets={'train': train_data, 'val': val_data}, \n",
    "                       device=device, \n",
    "                       num_epochs=epochs,\n",
    "                       lr=lr,\n",
    "                       momentum = momentum,\n",
    "                       trial=trial)\n",
    "\n",
    "\n",
    "    return(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-19 10:33:28,576] A new study created in RDB with name: 04 ResNet_1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2906 Acc: 41.16% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3629 Acc: 35.28% Kappa: 0.301\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2824 Acc: 42.34% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3617 Acc: 35.21% Kappa: 0.297\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2764 Acc: 42.43% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3614 Acc: 35.58% Kappa: 0.310\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2699 Acc: 42.48% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3621 Acc: 35.31% Kappa: 0.306\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2622 Acc: 43.46% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.38it/s]\n",
      "/tmp/ipykernel_1691189/4223688077.py:122: ExperimentalWarning:\n",
      "\n",
      "upload_artifact is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "\n",
      "/tmp/ipykernel_1691189/4223688077.py:124: ExperimentalWarning:\n",
      "\n",
      "upload_artifact is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3622 Acc: 35.55% Kappa: 0.310\n",
      "Training complete in 4m 59s\n",
      "Best val Acc: 35.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1691189/4223688077.py:129: ExperimentalWarning:\n",
      "\n",
      "upload_artifact is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "\n",
      "[I 2024-06-19 10:38:27,725] Trial 0 finished with value: 0.3097383240156475 and parameters: {'epochs': 5, 'lr': 0.002011262337616341, 'momentum': 0.10902563525065864}. Best is trial 0 with value: 0.3097383240156475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3021 Acc: 39.78% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4007 Acc: 34.68% Kappa: 0.270\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2098 Acc: 46.27% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4765 Acc: 30.28% Kappa: 0.230\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0743 Acc: 53.63% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5226 Acc: 30.11% Kappa: 0.177\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9007 Acc: 63.01% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6410 Acc: 30.64% Kappa: 0.203\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6893 Acc: 72.56% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.50it/s]\n",
      "[I 2024-06-19 10:43:26,045] Trial 1 finished with value: 0.2704338655533711 and parameters: {'epochs': 5, 'lr': 0.04251926496776635, 'momentum': 0.014269978621969614}. Best is trial 0 with value: 0.3097383240156475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.7876 Acc: 31.48% Kappa: 0.234\n",
      "Training complete in 4m 58s\n",
      "Best val Acc: 34.68%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2110 Acc: 45.52% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3698 Acc: 35.55% Kappa: 0.288\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1962 Acc: 47.44% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3646 Acc: 35.48% Kappa: 0.304\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1895 Acc: 48.89% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3644 Acc: 34.98% Kappa: 0.296\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1871 Acc: 49.05% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3636 Acc: 34.91% Kappa: 0.299\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1833 Acc: 49.57% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:07<00:00,  8.31it/s]\n",
      "[I 2024-06-19 10:48:24,776] Trial 2 finished with value: 0.30382318832937816 and parameters: {'epochs': 5, 'lr': 0.00019676675660946138, 'momentum': 0.2319990811141795}. Best is trial 0 with value: 0.3097383240156475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3648 Acc: 35.55% Kappa: 0.303\n",
      "Training complete in 4m 59s\n",
      "Best val Acc: 35.48%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=f'{MODEL_NAME}_{MODEL_VERSION}',\n",
    "                            load_if_exists = True)\n",
    "study.optimize(optuna_train, n_trials=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tomi-2RV3BUvH-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
