{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuentes: https://medium.com/nlplanet/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Instalar Modulos**\n",
    "\n",
    "conda install datasets==\"2.20.0\"\n",
    "\n",
    "conda install transformers==\"4.40.1\"\n",
    "\n",
    "conda install numpy==\"1.26.4\" # La última versión no funciona bien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa/miniconda3/envs/hf_diff_24/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset,  DatasetDict\n",
    "#from UA_MDM_LDI_II.tutoriales.utils import plot_confusion_matrix\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizerFast, DataCollatorWithPadding, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Verificamos que CUDA está funcional\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bajamos el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Armado de los Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = './'\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_IMAGES_DIR = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train_images\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_artifacts\")\n",
    "\n",
    "# Parametros y variables\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stringifying the column: 100%|██████████| 11984/11984 [00:00<00:00, 460707.21 examples/s]\n",
      "Casting to class labels: 100%|██████████| 11984/11984 [00:00<00:00, 408983.97 examples/s]\n",
      "Stringifying the column: 100%|██████████| 2996/2996 [00:00<00:00, 367366.39 examples/s]\n",
      "Casting to class labels: 100%|██████████| 2996/2996 [00:00<00:00, 302070.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID', 'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'AdoptionSpeed', '__index_level_0__']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "train_df = pd.read_csv(PATH_TO_TRAIN)\n",
    "train_df = train_df[train_df['Description'].notnull()]\n",
    "train_df['labels'] = train_df[\"AdoptionSpeed\"]\n",
    "\n",
    "# Dividir los datos usando sklearn\n",
    "train_df, test_df = train_test_split(train_df, test_size=TEST_SIZE, random_state=SEED, stratify=train_df.AdoptionSpeed)\n",
    "\n",
    "# Convertir a Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Combinar en un DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "# Codificar la columna de etiquetas como clases\n",
    "dataset = dataset.class_encode_column('labels')\n",
    "\n",
    "# Hacer una lista de columnas para remover antes de la tokenización\n",
    "cols_to_remove = [col for col in dataset[\"train\"].column_names if col != 'labels']\n",
    "print(cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener el objeto ClassLabel del conjunto de datos de entrenamiento\n",
    "class_label = dataset[\"train\"].features[\"labels\"]\n",
    "\n",
    "# Obtener las clases originales a partir del objeto ClassLabel\n",
    "classes = class_label.names\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   0%|          | 0/11984 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 11984/11984 [00:01<00:00, 6643.25 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 2996/2996 [00:00<00:00, 4919.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and encode the dataset\n",
    "def tokenize(batch):\n",
    "    from transformers import DistilBertTokenizerFast\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "    tokenized_batch = tokenizer(batch[\"Description\"], padding=True, truncation=True, max_length=512)\n",
    "    return tokenized_batch\n",
    "\n",
    "dataset_enc = dataset.map(tokenize, batched=True, remove_columns=cols_to_remove, num_proc=4)\n",
    "\n",
    "# Set dataset format for PyTorch\n",
    "dataset_enc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Check the output\n",
    "print(dataset_enc[\"train\"].column_names)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a data collator with dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Create data loaders for to reshape data for PyTorch model\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_enc[\"train\"], shuffle=True, batch_size=64, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset_enc[\"test\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Dynamically set number of class labels based on dataset\n",
    "num_labels = dataset[\"train\"].features['labels'].num_classes\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                                           num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa/miniconda3/envs/hf_diff_24/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 15\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Further define learning rate scheduler\n",
    "num_training_batches = len(train_dataloader)\n",
    "num_training_steps = num_epochs * num_training_batches\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",                   # linear decay\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miramos el Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set the device automatically (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2820/2820 [31:03<00:00,  1.93it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# Train the model with PyTorch training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtenemos la kappa base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Weighted Kappa: 0.22744284573893092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Inicializa listas para almacenar todas las predicciones y etiquetas\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iteratively evaluate the model and collect predictions and labels\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # Mover predicciones y etiquetas a CPU y convertir a numpy\n",
    "    all_predictions.extend(predictions.cpu().numpy())\n",
    "    all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Convertir listas a arrays de numpy\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Calcular Quadratic Weighted Kappa\n",
    "qwk = cohen_kappa_score(all_labels, all_predictions, weights='quadratic')\n",
    "\n",
    "print(f\"Quadratic Weighted Kappa: {qwk}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predecimos un ejemplo de descripción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cute active little puppy found abondoned and looking for a loving home to live. Please adopt me.....\n",
      "[0.01477182 0.25765750 0.34577578 0.31173441 0.07006051]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Un ejemplo\n",
    "desc = test_df.iloc[4]['Description']\n",
    "print(desc)\n",
    "\n",
    "# Tokenize inputs\n",
    "inputs = tokenizer(desc, padding=True, truncation=True, return_tensors=\"pt\").to(device) # Move the tensor to the GPU\n",
    "\n",
    "# Inference model and get logits\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Convert logits to class probabilities\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "probabilities = predictions.detach().cpu().numpy()\n",
    "predicted_class = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Establecer opciones de impresión para evitar la notación científica\n",
    "np.set_printoptions(suppress=True, formatter={'float_kind': '{:.8f}'.format})\n",
    "print(probabilities[0])\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tomi-2RV3BUvH-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
